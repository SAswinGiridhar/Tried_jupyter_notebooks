{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT Tutorial 1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsIU8GXSUQDI",
        "colab_type": "text"
      },
      "source": [
        "# **Google BERT Transformers with Pytorch Example** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAUXCyYdUtnE",
        "colab_type": "text"
      },
      "source": [
        "**BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding**\n",
        "\n",
        "\n",
        "PyTorch Transformers can be installed using pip below and few pre-requisites:\n",
        "*   So change the Run Time type to GPU \n",
        "*   Use version Python 3.5+ and PyTorch 1.1.0\n",
        "*   Import the required Libraries\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VA_5qKN0iSVl",
        "colab_type": "text"
      },
      "source": [
        "## What is BERT?\n",
        "A new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. BERT is designed to pre- train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a re- sult, the pre-trained BERT model can be fine- tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task- specific architecture modifications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87HjTjkqAq_K",
        "colab_type": "text"
      },
      "source": [
        "There are a few things I want to explain in this section.\n",
        "\n",
        "1. It’s easy to get that BERT stands for Bidirectional Encoder Representations from Transformers. Each word here has a meaning to it and we will encounter that one by one. For now, the key takeaway from this line is – BERT is based on the Transformer architecture.\n",
        "\n",
        "2. BERT is pre-trained on a large corpus of unlabelled text including the entire Wikipedia(that’s 2,500 million words!) and Book Corpus (800 million words). This pretraining step is really important for BERT's success. This is because as we train a model on a large text corpus, our model starts to pick up the deeper and intimate understandings of how the language works. This knowledge is the swiss army knife that is useful for almost any NLP task.\n",
        "\n",
        "3. BERT is a deeply bidirectional model. Bidirectional means that BERT learns information from both the left and the right side of a token’s context during the training phase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2cAxP2uAX5P",
        "colab_type": "text"
      },
      "source": [
        "BERT was built upon recent work in pre-training contextual representations — including Semi-supervised Sequence Learning, Generative Pre-Training, ELMo, and ULMFit — but crucially these models are all unidirectional or shallowly bidirectional. This means that each word is only contextualized using the words to its left (or right). \n",
        "\n",
        "\n",
        "\n",
        "For example, in the sentence I made a bank deposit the unidirectional representation of bank is only based on I made a but not deposit. Some previous work does combine the representations from separate left-context and right-context models, but only in a \"shallow\" manner.\n",
        "\n",
        " **Example**- BERT represents \"bank\" using both its left and right context — \n",
        " **I made a ... deposit** — starting from the very bottom of a deep neural network, so it is deeply bidirectional."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3IZV5jjBttx",
        "colab_type": "text"
      },
      "source": [
        "![](https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2019/09/sent_context.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mgo0da8mCGB2",
        "colab_type": "text"
      },
      "source": [
        "## Main concepts\n",
        "\n",
        "The library is build around three type of classes for each models:\n",
        "\n",
        "1. **model classes** which are PyTorch models (torch.nn.Modules) of the 8 models architectures currently provided in the library, e.g. BertModel\n",
        "2. **configuration classes** which store all the parameters required to build a model, e.g. BertConfig. You don’t always need to instantiate these your-self, in particular if you are using a pretrained model without any modification, creating the model will automatically take care of instantiating the configuration (which is part of the model)\n",
        "3. **tokenizer classes** which store the vocabulary for each model and provide methods for encoding/decoding strings in list of token embeddings indices to be fed to a model, e.g. BertTokenizer\n",
        "All these classes can be instantiated from pretrained instances and saved locally using two methods:\n",
        "\n",
        "**from_pretrained()** let you instantiate a model/configuration/tokenizer from a pretrained version either provided by the library itself (currently 27 models are provided as listed here) or stored locally (or on a server) by the user.\n",
        "\n",
        "**save_pretrained()** let you save a model/configuration/tokenizer locally so that it can be reloaded using from_pretrained()."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Go6_nxwchPB",
        "colab_type": "text"
      },
      "source": [
        "### 1. Bert Model Architecture\n",
        "\n",
        "BERT’s model architecture is a multi-layer bidirectional Transformer encoder\n",
        "\n",
        "1. **BERT-Large, Uncased (Whole Word Masking)**: 24-layer, 1024-hidden, 16-heads, 340M parameters\n",
        "2. **BERT-Large, Cased (Whole Word Masking)**: 24-layer, 1024-hidden, 16-heads, 340M parameters\n",
        "3. **BERT-Base, Uncased**: 12-layer, 768-hidden, 12-heads, 110M parameters\n",
        "4. **BERT-Large, Uncased**: 24-layer, 1024-hidden, 16-heads, 340M parameters\n",
        "5. **BERT-Base, Cased**: 12-layer, 768-hidden, 12-heads , 110M parameters\n",
        "6. **BERT-Large, Cased**: 24-layer, 1024-hidden, 16-heads, 340M parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gs1mCcR-gWC0",
        "colab_type": "text"
      },
      "source": [
        "![](http://jalammar.github.io/images/bert-base-bert-large-encoders.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVA8QwkmkJAI",
        "colab_type": "text"
      },
      "source": [
        "We denote the number of layers (i.e., Transformer blocks) \n",
        "as **L**, the **hidden size** as **H**, and \n",
        "the number of self-attention heads as We primarily report results on \n",
        "two model sizes: \n",
        "1. **BERTBASE (L=12, H=768, A=12, Total Parameters=110M)** \n",
        "2. **BERTLARGE (L=24, H=1024, A=16, Total Parameters=340M)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXhYHZbhVh92",
        "colab_type": "text"
      },
      "source": [
        "Load pre-trained model tokenizer (vocabulary)\n",
        "The base class PreTrainedTokenizer implements the common methods for loading/saving a tokenizer either from a local file or directory, or from a pretrained tokenizer provided by the library (downloaded from HuggingFace’s AWS S3 repository)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pPb2PwZFwZB",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "class transformers.BertModel\n",
        "```\n",
        "Parameters\n",
        "*   config (BertConfig) – Model configuration class with all the parameters of the model. Initializing with a config file does not load the weights associated with the model, only the configuration. Check out the from_pretrained() method to load the model weights.\n",
        "\n",
        "**Example**\n",
        "Indices of input sequence tokens in the vocabulary. To match pre-training, BERT input sequence should be formatted with [CLS] and [SEP] tokens as follows:\n",
        "\n",
        "1. **For sequence pairs:**\n",
        "\n",
        "tokens: [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
        "\n",
        "token_type_ids: 0   0  0    0    0    0    0   0   1  1  1  1 1   1\n",
        "\n",
        "2. **For single sequences:**\n",
        "\n",
        "tokens:[CLS] the dog is hairy . [SEP]\n",
        "\n",
        "token_type_ids:   0   0   0   0  0     0   0\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqoLtjmRVzzV",
        "colab_type": "text"
      },
      "source": [
        "### 2. Bert Tokenizer\n",
        "**BertTokenizer** = Tokenizer classes which store the vocabulary for each model and provide methods for encoding/decoding strings in list of token embeddings indices to be fed to a model eg DistilBertTokenizer,BertTokenizer etc\n",
        "![](https://jalammar.github.io/images/distilBERT/bert-distilbert-tokenization-1.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VHjPc7rXoVy",
        "colab_type": "text"
      },
      "source": [
        "**PreTrainedTokenizer** is the main entry point into tokenizers as it also implements the main methods for using all the tokenizers:\n",
        "\n",
        "*   tokenizing, converting tokens to ids and back and encoding/decoding,\n",
        "*   adding new tokens to the vocabulary in a way that is independant of the underlying structure (BPE, SentencePiece…),\n",
        "*   managing special tokens (adding them, assigning them to roles, making sure they are not split during tokenization)\n",
        "\n",
        "**Main Class from where the Tokenizer is been called**\n",
        "```\n",
        "class transformers.BertTokenizer(vocab_file, do_lower_case=True, do_basic_tokenize=True, never_split=None, unk_token='[UNK]', sep_token='[SEP]', pad_token='[PAD]', cls_token='[CLS]', mask_token='[MASK]', tokenize_chinese_chars=True, **kwargs)\n",
        "\n",
        "```\n",
        "\n",
        "*Parameters*\n",
        "\n",
        "\n",
        "*  **vocab_file** – Path to a one-wordpiece-per-line vocabulary file\n",
        "*  **do_lower_case** – Whether to lower case the input. Only has an effect when                     do_basic_tokenize=True\n",
        "\n",
        "*  **do_basic_tokenize** – Whether to do basic tokenization before wordpiece.\n",
        "*  **max_len** – An artificial maximum length to truncate tokenized sequences to; Effective maximum length is always the minimum of this value (if             specified) and the underlying BERT model’s sequence length.\n",
        "\n",
        "*   **never_split** – List of tokens which will never be split during                        tokenization. Only has an effect when do_basic_tokenize=True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-Ji4oGwanPv",
        "colab_type": "text"
      },
      "source": [
        "![](https://www.researchgate.net/publication/323904682/figure/fig1/AS:606458626465792@1521602412057/The-Transformer-model-architecture.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8bBNBora1BJ",
        "colab_type": "text"
      },
      "source": [
        "So to have a detail architecture of how Encoder-Decoder works here is few [Link1](https://arxiv.org/pdf/1706.03762.pdf) & visual [Link2](http://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiXGe7Qlcy3v",
        "colab_type": "text"
      },
      "source": [
        "**ARCHITECTURE**: \n",
        "1. **Encoder**: The encoder is composed of a stack of N = 6 identical layers. Each layer has two sub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position- wise fully connected feed-forward network. We employ a residual connection [11] around each of the two sub-layers, followed by layer normalization [1]. That is, the output of each sub-layer is LayerNorm(x + Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer itself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding layers, produce outputs of dimension dmodel = 512.\n",
        "\n",
        "2. **Decoder:** The decoder is also composed of a stack of N = 6 identical layers. In addition to the two sub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head attention over the output of the encoder stack. Similar to the encoder, we employ residual connections around each of the sub-layers, followed by layer normalization. We also modify the self-attention sub-layer in the decoder stack to prevent positions from attending to subsequent positions. This masking, combined with fact that the output embeddings are offset by one position, ensures that the predictions for position i can depend only on the known outputs at positions less than i."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RJLtIdAX5lX",
        "colab_type": "text"
      },
      "source": [
        "Let’s try to classify the sentence “a visually stunning rumination on love”. The first step is to use the BERT tokenizer to first split the word into tokens. Then, we add the special tokens needed for sentence classifications (these are [CLS] at the first position, and [SEP] at the end of the sentence).\n",
        "\n",
        "[CLS] is a special symbol added in front of every input example, and [SEP] is a special separator token (e.g. separating ques- tions/answers)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Fc-rFzfEDim",
        "colab_type": "text"
      },
      "source": [
        "![](https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2019/09/bert_emnedding.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0t0i3LnbFNjN",
        "colab_type": "text"
      },
      "source": [
        "BERT input representation. The **input embeddings** are the sum of the **token embeddings**, the **segmentation embeddings** and **the position embeddings**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85eRapWMEigo",
        "colab_type": "text"
      },
      "source": [
        "1. The first token of every sequence is always a special clas- sification token (**[CLS]**). \n",
        "2. The final hidden state corresponding to this token is used as the ag- gregate sequence representation for classification tasks. Sentence pairs are packed together into a single sequence.\n",
        "3. We differentiate the sentences in two ways. First, we separate them with a special token (**[SEP]**). Second, we add a learned embed- ding to every token indicating whether it belongs to sentence A or sentence B. \n",
        "4.A positional embedding is also added to each token to indicate its position in the sequence.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mePP9GjSCpm9",
        "colab_type": "text"
      },
      "source": [
        "### 3. Configuration Class\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gf1CkpfrGy0g",
        "colab_type": "text"
      },
      "source": [
        "The base class PretrainedConfig implements the common methods for loading/saving a configuration either from a local file or directory, or from a pretrained model configuration provided by the library (downloaded from HuggingFace’s AWS S3 repository).\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "class transformers.PretrainedConfig(**kwargs)\n",
        "```\n",
        "Base class for all configuration classes. Handles a few parameters common to all models’ configurations as well as methods for loading/downloading/saving configurations.\n",
        "\n",
        "*Parameters*\n",
        "\n",
        "*  **finetuning_task** – string, default None. Name of the task used to fine-tune the model. This can be used when converting from an original (TensorFlow or PyTorch) checkpoint.\n",
        "\n",
        "*   **num_labels** – integer, default 2. Number of classes to use when the model is a classification model (sequences/tokens)\n",
        "*   **output_hidden_states** – string, default False. Should the model returns all hidden-states.\n",
        "\n",
        "*   **output_attentions** – boolean, default False. Should the model returns attentions weights.\n",
        "*   **torchscript** – string, default False. Is the model used with Torchscript.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WddVtaL9J92w",
        "colab_type": "text"
      },
      "source": [
        "# Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZYdnHUpIklM",
        "colab_type": "text"
      },
      "source": [
        "Using BERT has two stages: Pre-training and fine-tuning.\n",
        "\n",
        "**Pre-training** :It is fairly expensive (four days on 4 to 16 Cloud TPUs), but is a one-time procedure for each language (current models are English-only, but multilingual models will be released in the near future). We are releasing a number of pre-trained models from the paper which were pre-trained at Google. Most NLP researchers will never need to pre-train their own model from scratch.\n",
        "\n",
        "**Fine-tuning** : It is inexpensive. All of the results in the paper can be replicated in at most 1 hour on a single Cloud TPU, or a few hours on a GPU, starting from the exact same pre-trained model. SQuAD, for example, can be trained in around 30 minutes on a single Cloud TPU to achieve a Dev F1 score of 91.0%, which is the single system state-of-the-art.\n",
        "\n",
        "\n",
        "![](https://insidebigdata.com/wp-content/uploads/2019/10/Peltarion_pic2.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iITsqEiLJJGd",
        "colab_type": "text"
      },
      "source": [
        "Here we will see two pre-trained Models\n",
        "> *Model 1*: **Masked LM**\n",
        "\n",
        "> *Model 2*: **Next Sentence Prediction (NSP)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khJSahp4bReO",
        "colab_type": "text"
      },
      "source": [
        "## Model 1:Masked LM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiV-JiwbbXE-",
        "colab_type": "text"
      },
      "source": [
        "**STEPS**\n",
        "\n",
        "1. Deep bidirectional model is strictly more powerful than either a left-to-right model or the shallow concatenation of a left-to- right and a right-to-left model. \n",
        " the model could trivially predict the target word in a multi-layered context.\n",
        "\n",
        "2. In order to train a deep bidirectional representa- tion, we simply mask some percentage of the input tokens at random, and then predict those masked tokens. \n",
        "\n",
        "3. In this case, the final hidden vectors corresponding to the mask tokens are fed into an output softmax over the vocabulary, as in a standard LM. \n",
        "\n",
        "\n",
        "Although this allows us to obtain a bidirectional pretrained model, a downside is that we are creating a mismatch between pre-training and fine-tuning, since the **[MASK]** token does not appear during fine-tuning. To mitigate this, we do not always replace “masked” words with the actual **[MASK]** token. \n",
        "\n",
        "**1 Problem:** Language models only use left context or right context, but language understanding is bidirectional.\n",
        "\n",
        "● Why are LMs unidirectional?\n",
        "\n",
        "*Reason 1:* Directionality is needed to generate a\n",
        "well-formed probability distribution.\n",
        "\n",
        "    ○ We don’t care about this.\n",
        "● \n",
        "*Reason 2:* Words can “see themselves” in a bidirectional encoder.\n",
        "\n",
        "**Solution:** Mask out k% of the input words, \n",
        "and then predict the masked words\n",
        "○ We always use k = 15%\n",
        "\n",
        "\n",
        "                                store                 gallon\n",
        "                                  |                    |\n",
        "          the man went to the **[MASK]**  to buy a **[MASK]**  of milk\n",
        "\n",
        "● Too little masking: Too expensive to train\n",
        "\n",
        "● Too much masking: Not enough context\n",
        "\n",
        "\n",
        "\n",
        "**2 Problem:** Mask token never seen at fine-tuning\n",
        "\n",
        "**Solution:** 15% of the words to predict, but don’t\n",
        "replace with **[MASK]** 100% of the time. Instead:\n",
        "\n",
        "● 80% of the time, replace with **[MASK]** \n",
        "went to the store → went to the **[MASK]** \n",
        "\n",
        "● 10% of the time, replace random word\n",
        "went to the store → went to the running\n",
        "\n",
        "● 10% of the time, keep same\n",
        "went to the store → went to the store\n",
        "\n",
        "\n",
        "If the i-th token is chosen, we replace the i-th token with Then, Ti will be used to predict the original token with cross entropy loss.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AInZF3z5IOru",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 753
        },
        "outputId": "d19d9c7b-5185-4d70-a69e-db83261f0343"
      },
      "source": [
        "!pip install transformers\n",
        "# OPTIONAL: if you want to have more information on what's happening under the hood, activate the logger as follows\n",
        "import logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel, BertForMaskedLM"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/10/aeefced99c8a59d828a92cc11d213e2743212d3641c87c82d61b035a7d5c/transformers-2.3.0-py3-none-any.whl (447kB)\n",
            "\r\u001b[K     |▊                               | 10kB 33.1MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20kB 2.1MB/s eta 0:00:01\r\u001b[K     |██▏                             | 30kB 2.9MB/s eta 0:00:01\r\u001b[K     |███                             | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |███▋                            | 51kB 2.4MB/s eta 0:00:01\r\u001b[K     |████▍                           | 61kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 71kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 92kB 3.7MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 102kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████                        | 112kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 122kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 133kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 143kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 153kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 163kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 174kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 184kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 194kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 204kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 215kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 225kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 235kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 245kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 256kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 266kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 276kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 286kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 296kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 307kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 317kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 327kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 337kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 348kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 358kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 368kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 378kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 389kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 399kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 409kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 419kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 430kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 440kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 450kB 3.4MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\r\u001b[K     |▎                               | 10kB 37.2MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 32.0MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 39.9MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 25.9MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 20.0MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 22.8MB/s eta 0:00:01\r\u001b[K     |██▏                             | 71kB 15.9MB/s eta 0:00:01\r\u001b[K     |██▌                             | 81kB 15.1MB/s eta 0:00:01\r\u001b[K     |██▉                             | 92kB 16.6MB/s eta 0:00:01\r\u001b[K     |███▏                            | 102kB 15.9MB/s eta 0:00:01\r\u001b[K     |███▌                            | 112kB 15.9MB/s eta 0:00:01\r\u001b[K     |███▉                            | 122kB 15.9MB/s eta 0:00:01\r\u001b[K     |████                            | 133kB 15.9MB/s eta 0:00:01\r\u001b[K     |████▍                           | 143kB 15.9MB/s eta 0:00:01\r\u001b[K     |████▊                           | 153kB 15.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 163kB 15.9MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 174kB 15.9MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 184kB 15.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 194kB 15.9MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 204kB 15.9MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 215kB 15.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 225kB 15.9MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 235kB 15.9MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 245kB 15.9MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 256kB 15.9MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 266kB 15.9MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 276kB 15.9MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 286kB 15.9MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 296kB 15.9MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 307kB 15.9MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 317kB 15.9MB/s eta 0:00:01\r\u001b[K     |██████████                      | 327kB 15.9MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 337kB 15.9MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 348kB 15.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 358kB 15.9MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 368kB 15.9MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 378kB 15.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 389kB 15.9MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 399kB 15.9MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 409kB 15.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 419kB 15.9MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 430kB 15.9MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 440kB 15.9MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 450kB 15.9MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 460kB 15.9MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 471kB 15.9MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 481kB 15.9MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 491kB 15.9MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 501kB 15.9MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 512kB 15.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 522kB 15.9MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 532kB 15.9MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 542kB 15.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 552kB 15.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 563kB 15.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 573kB 15.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 583kB 15.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 593kB 15.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 604kB 15.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 614kB 15.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 624kB 15.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 634kB 15.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 645kB 15.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 655kB 15.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 665kB 15.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 675kB 15.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 686kB 15.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 696kB 15.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 706kB 15.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 716kB 15.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 727kB 15.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 737kB 15.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 747kB 15.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 757kB 15.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 768kB 15.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 778kB 15.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 788kB 15.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 798kB 15.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 808kB 15.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 819kB 15.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 829kB 15.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 839kB 15.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 849kB 15.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 860kB 15.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 870kB 15.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 880kB 15.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 890kB 15.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 901kB 15.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 911kB 15.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 921kB 15.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 931kB 15.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 942kB 15.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 952kB 15.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 962kB 15.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 972kB 15.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 983kB 15.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 993kB 15.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.0MB 15.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.0MB 15.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.0MB 15.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.0MB 15.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0MB 15.9MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\r\u001b[K     |▍                               | 10kB 32.7MB/s eta 0:00:01\r\u001b[K     |▊                               | 20kB 44.7MB/s eta 0:00:01\r\u001b[K     |█▏                              | 30kB 54.8MB/s eta 0:00:01\r\u001b[K     |█▌                              | 40kB 36.5MB/s eta 0:00:01\r\u001b[K     |██                              | 51kB 23.9MB/s eta 0:00:01\r\u001b[K     |██▎                             | 61kB 27.2MB/s eta 0:00:01\r\u001b[K     |██▋                             | 71kB 22.8MB/s eta 0:00:01\r\u001b[K     |███                             | 81kB 19.5MB/s eta 0:00:01\r\u001b[K     |███▍                            | 92kB 21.4MB/s eta 0:00:01\r\u001b[K     |███▉                            | 102kB 19.7MB/s eta 0:00:01\r\u001b[K     |████▏                           | 112kB 19.7MB/s eta 0:00:01\r\u001b[K     |████▋                           | 122kB 19.7MB/s eta 0:00:01\r\u001b[K     |█████                           | 133kB 19.7MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 143kB 19.7MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 153kB 19.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 163kB 19.7MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 174kB 19.7MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 184kB 19.7MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 194kB 19.7MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 204kB 19.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 215kB 19.7MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 225kB 19.7MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 235kB 19.7MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 245kB 19.7MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 256kB 19.7MB/s eta 0:00:01\r\u001b[K     |██████████                      | 266kB 19.7MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 276kB 19.7MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 286kB 19.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 296kB 19.7MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 307kB 19.7MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 317kB 19.7MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 327kB 19.7MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 337kB 19.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 348kB 19.7MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 358kB 19.7MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 368kB 19.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 378kB 19.7MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 389kB 19.7MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 399kB 19.7MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 409kB 19.7MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 419kB 19.7MB/s eta 0:00:01\r\u001b[K     |████████████████                | 430kB 19.7MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 440kB 19.7MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 450kB 19.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 460kB 19.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 471kB 19.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 481kB 19.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 491kB 19.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 501kB 19.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 512kB 19.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 522kB 19.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 532kB 19.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 542kB 19.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 552kB 19.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 563kB 19.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 573kB 19.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 583kB 19.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 593kB 19.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 604kB 19.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 614kB 19.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 624kB 19.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 634kB 19.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 645kB 19.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 655kB 19.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 665kB 19.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 675kB 19.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 686kB 19.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 696kB 19.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 706kB 19.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 716kB 19.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 727kB 19.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 737kB 19.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 747kB 19.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 757kB 19.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 768kB 19.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 778kB 19.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 788kB 19.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 798kB 19.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 808kB 19.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 819kB 19.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 829kB 19.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 839kB 19.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 849kB 19.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 860kB 19.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 870kB 19.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.10.47)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.47 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.13.47)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884629 sha256=53b4ef4a5ba475814fabf2688e849c0312653c016e537b38cb501ebbafa91225\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 transformers-2.3.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.file_utils:PyTorch version 1.3.1 available.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Azh1mYBfcZKE",
        "colab_type": "code",
        "outputId": "ee2ce9f0-dc5f-4196-8be1-b00d64e92b4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmp71n9nbk5\n",
            "INFO:transformers.file_utils:copying /tmp/tmp71n9nbk5 to cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "INFO:transformers.file_utils:removing temp file /tmp/tmp71n9nbk5\n",
            "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdEqm_R3ccHX",
        "colab_type": "code",
        "outputId": "e94152d8-aefe-40e5-91f8-0bf1822fabb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# Tokenize input\n",
        "text  = \"[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]\"\n",
        "tokenized_text = tokenizer.tokenize(text)\n",
        "tokenized_text.T"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'who',\n",
              " 'was',\n",
              " 'jim',\n",
              " 'henson',\n",
              " '?',\n",
              " '[SEP]',\n",
              " 'jim',\n",
              " 'henson',\n",
              " 'was',\n",
              " 'a',\n",
              " 'puppet',\n",
              " '##eer',\n",
              " '[SEP]']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOB1PfvSfZbM",
        "colab_type": "text"
      },
      "source": [
        "Here MASK is a word we will predict between the sentence\n",
        "\n",
        "\n",
        "**TOKEN EMBEDDINGS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IGr3YHRchsk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mask a token that we will try to predict back with `BertForMaskedLM`\n",
        "masked_index = 8\n",
        "tokenized_text[masked_index] = '[MASK]'\n",
        "assert tokenized_text == ['[CLS]', 'who', 'was', 'jim', 'henson', '?', '[SEP]', 'jim', '[MASK]', 'was', 'a', 'puppet', '##eer', '[SEP]']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQME6Hyzc9bN",
        "colab_type": "code",
        "outputId": "de99b014-b1c2-4296-c3d8-5b02f51dd638",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "tokenized_text"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'who',\n",
              " 'was',\n",
              " 'jim',\n",
              " 'henson',\n",
              " '?',\n",
              " '[SEP]',\n",
              " 'jim',\n",
              " '[MASK]',\n",
              " 'was',\n",
              " 'a',\n",
              " 'puppet',\n",
              " '##eer',\n",
              " '[SEP]']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYFFDHAXhDE3",
        "colab_type": "text"
      },
      "source": [
        "**POSITION EMBEDDINGS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prohNWKVcjfx",
        "colab_type": "code",
        "outputId": "cef4472d-ed1d-4418-a0ce-968bedbe6e58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# Convert token to vocabulary indices\n",
        "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "indexed_tokens"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101,\n",
              " 2040,\n",
              " 2001,\n",
              " 3958,\n",
              " 27227,\n",
              " 1029,\n",
              " 102,\n",
              " 3958,\n",
              " 103,\n",
              " 2001,\n",
              " 1037,\n",
              " 13997,\n",
              " 11510,\n",
              " 102]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5J4NYdQhln7",
        "colab_type": "text"
      },
      "source": [
        "**SEGMENT EMBEDDINGS**\n",
        "\n",
        "Here from the tokenized tokens which are part of one sentence we indexing with a 0,1 respectively for each sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8WapubcclMV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define sentence A and B indices associated to 1st and 2nd sentences (see paper)\n",
        "segments_ids = [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djEHZYr7cm1G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert inputs to PyTorch tensors\n",
        "tokens_tensor = torch.tensor([indexed_tokens])\n",
        "segments_tensors = torch.tensor([segments_ids])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09_n9_ifdZHS",
        "colab_type": "code",
        "outputId": "92ddf412-b87a-41eb-8d6c-1dc921e97947",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 831
        }
      },
      "source": [
        "# Load pre-trained model (weights)\n",
        "model = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmppr8sras4\n",
            "INFO:transformers.file_utils:copying /tmp/tmppr8sras4 to cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
            "INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
            "INFO:transformers.file_utils:removing temp file /tmp/tmppr8sras4\n",
            "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
            "INFO:transformers.configuration_utils:Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "INFO:transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmp8uvak1jx\n",
            "INFO:transformers.file_utils:copying /tmp/tmp8uvak1jx to cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "INFO:transformers.file_utils:creating metadata file for /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "INFO:transformers.file_utils:removing temp file /tmp/tmp8uvak1jx\n",
            "INFO:transformers.modeling_utils:loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzLgAl3Ilti8",
        "colab_type": "text"
      },
      "source": [
        "**Hyperparameter Tuning**\n",
        "  1. layer_norm_eps: 1e-12\n",
        "  2. max_position_embeddings: 512\n",
        "  3. num_attention_heads: 12\n",
        "  4. num_hidden_layers: 12\n",
        "  5. num_labels: 2\n",
        "  10. torchscript: false\n",
        "  11. type_vocab_size: 2\n",
        "  13. vocab_size: 30522"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vR9k4P5disP",
        "colab_type": "code",
        "outputId": "4beaff9e-abde-4ad6-d456-9db430e57d21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Set the model in evaluation mode to deactivate the DropOut modules\n",
        "# This is IMPORTANT to have reproducible results during evaluation!\n",
        "model.eval()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BoPAjibdlkt",
        "colab_type": "code",
        "outputId": "7f5efda9-9d94-4588-a724-0c4e466ed751",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# If you have a GPU, put everything on cuda\n",
        "tokens_tensor = tokens_tensor.to('cuda')\n",
        "segments_tensors = segments_tensors.to('cuda')\n",
        "model.to('cuda')\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcIqReM6d_nQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Predict hidden states features for each layer\n",
        "with torch.no_grad():\n",
        "    # See the models docstrings for the detail of the inputs\n",
        "    outputs = model(tokens_tensor, token_type_ids=segments_tensors)\n",
        "    # Transformers models always output tuples.\n",
        "    # See the models docstrings for the detail of all the outputs\n",
        "    # In our case, the first element is the hidden state of the last layer of the Bert model\n",
        "    encoded_layers = outputs[0]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BLZ8_uifLaX",
        "colab_type": "code",
        "outputId": "6c99cc7f-9464-418d-fb61-fc999c8de066",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "encoded_layers.shape\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 14, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eW66dStfj-_V",
        "colab_type": "text"
      },
      "source": [
        " So from the above shape we have 3D tensor.\n",
        " **SHAPE(BATCH SIZE,TOKENS,HIDDEN UNITS)**\n",
        "\n",
        ">  **1** represents one sentence\n",
        "\n",
        ">  **14** represents number of total tokens after tokenization\n",
        "\n",
        ">  **768** the number of hidden units in the **Bert model Uncased**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gofsKTVpj1wE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b2daadf0-6dfa-48c4-df93-371d7da3093d"
      },
      "source": [
        "print(len(indexed_tokens), model.config.hidden_size)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14 768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "362pUiQheC2U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We have encoded our input sequence in a FloatTensor of shape (batch size, sequence length, model hidden dimension)\n",
        "assert tuple(encoded_layers.shape) == (1, len(indexed_tokens), model.config.hidden_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yemSMWgDfbtY",
        "colab_type": "code",
        "outputId": "3bead3f9-6ad0-433a-9f3e-a8401ed8ffcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Load pre-trained model (weights)\n",
        "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
        "model.eval()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
            "INFO:transformers.configuration_utils:Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "INFO:transformers.modeling_utils:loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "INFO:transformers.modeling_utils:Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForMaskedLM(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (cls): BertOnlyMLMHead(\n",
              "    (predictions): BertLMPredictionHead(\n",
              "      (transform): BertPredictionHeadTransform(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (decoder): Linear(in_features=768, out_features=30522, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lFBXOWvfs1X",
        "colab_type": "code",
        "outputId": "82750609-ab7e-45db-9043-333b60a6af84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# If you have a GPU, put everything on cuda\n",
        "tokens_tensor = tokens_tensor.to('cuda')\n",
        "segments_tensors = segments_tensors.to('cuda')\n",
        "model.to('cuda')\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForMaskedLM(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (cls): BertOnlyMLMHead(\n",
              "    (predictions): BertLMPredictionHead(\n",
              "      (transform): BertPredictionHeadTransform(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (decoder): Linear(in_features=768, out_features=30522, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsIoJsv5gOZ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict all tokens\n",
        "with torch.no_grad():\n",
        "    outputs = model(tokens_tensor, token_type_ids=segments_tensors)\n",
        "    predictions = outputs[0]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbvpC5tOgVIX",
        "colab_type": "code",
        "outputId": "580011ec-fbe0-4205-a432-6e9946388b8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "predictions"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ -7.8798,  -7.7874,  -7.7861,  ...,  -7.0438,  -6.7454,  -4.6013],\n",
              "         [-13.3633, -13.7694, -13.7819,  ..., -11.8128, -11.1635, -13.8906],\n",
              "         [-10.9775, -10.5383, -10.9659,  ..., -11.5549,  -8.0309,  -6.3979],\n",
              "         ...,\n",
              "         [ -5.2284,  -5.6572,  -5.3550,  ...,  -3.4507,  -3.8718,  -8.6904],\n",
              "         [ -8.5290,  -8.4146,  -9.0744,  ...,  -7.1710,  -6.9877,  -6.1301],\n",
              "         [-12.5968, -12.3769, -12.4222,  ..., -10.1020,  -9.8764,  -9.4495]]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fEdAPEAgRYV",
        "colab_type": "code",
        "outputId": "5f8a4f94-4cde-4313-a250-73ca4f80a27b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# confirm we were able to predict 'henson'\n",
        "predicted_index = torch.argmax(predictions[0, masked_index]).item()\n",
        "\n",
        "predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n",
        "print(predicted_index,predicted_token)\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "27227 henson\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TkRUsuhgkb9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert predicted_token == 'henson'"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}